{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization, UpSampling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.models import *\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\train1\\\\'\n",
    "train2 = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\train2\\\\'\n",
    "train3 = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\train3\\\\'\n",
    "train4 = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\train4\\\\'\n",
    "train5 = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\train5\\\\'\n",
    "\n",
    "train_4 = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\trai_n\\\\'\n",
    "train_5 = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\train\\\\'\n",
    "test = 'C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\dog_cat_new\\\\test\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum']\n",
      "(5600, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5600, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train1))\n",
    "p4=0\n",
    "d4=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train1 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs4=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs4 = np.append(imgs4, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d4.append(res)\n",
    "print(d4)\n",
    "    \n",
    "print(imgs4.shape)\n",
    "        \n",
    "img_data = np.array(imgs4)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs4 = imgs4.reshape(-1,28,28,1)\n",
    "#test_images = test_images.reshape(-1,256,256,1)\n",
    "imgs4.shape#,test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs4 = imgs4 / np.max(imgs4)\n",
    "#test_images = test_images / np.max(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,valid_X,train_ground,valid_ground = train_test_split(imgs4,imgs4,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape = (28,28,1))\n",
    "def encoder(input):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def decoder(conv3):    \n",
    "    #decoder\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded\n",
    "\n",
    "\n",
    "autoencoder = Model(input, decoder(encoder(input)))\n",
    "autoencoder.compile(loss='mean_squared_error', optimizer = 'rmsprop',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 3s 21ms/step - loss: 0.1006 - acc: 0.0114 - val_loss: 0.0840 - val_acc: 0.0411\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0360 - acc: 0.0135 - val_loss: 0.0336 - val_acc: 0.0421\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0261 - acc: 0.0137 - val_loss: 0.0282 - val_acc: 0.0421\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0375 - acc: 0.0134 - val_loss: 0.0366 - val_acc: 0.0419\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0244 - acc: 0.0137 - val_loss: 0.0410 - val_acc: 0.0421\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train = autoencoder.fit(train_X, train_ground, batch_size=32,epochs=5,verbose=1,validation_data=(valid_X, valid_ground))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.040956272184848784, 0.04212372414767742]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.evaluate(valid_X, valid_ground,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum']\n",
      "(5600, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5600, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train1))\n",
    "p4=0\n",
    "d4=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train1 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs4=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs4 = np.append(imgs4, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d4.append(res)\n",
    "print(d4)\n",
    "    \n",
    "print(imgs4.shape)\n",
    "        \n",
    "img_data = np.array(imgs4)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (134, 28, 28) 134\n",
      "Testing data shape :  (66, 28, 28) 66\n",
      "Total number of outputs :  4\n",
      "Output classes :  ['cat' 'dog' 'hor' 'hum']\n"
     ]
    }
   ],
   "source": [
    "imgs4 = np.reshape(imgs4, [ 200, 28, 28])\n",
    "imgs = np.reshape(imgs4, [ 200, 28, 28])\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(imgs4, d4, test_size=0.33, random_state=42)\n",
    "print('Training data shape : ', train_images.shape, len(train_labels))\n",
    "print('Testing data shape : ', test_images.shape, len(test_labels))\n",
    "classes = np.unique(train_labels)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels=[0 if x=='cat' else 1 for x in train_labels]\n",
    "print(train_labels)\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels=[0 if x=='cat' else 1 for x in test_labels]\n",
    "print(test_labels)\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "134\n",
      "66\n",
      "Original label :  1\n",
      "After conversion to categorical ( one-hot ) :  [0. 1.]\n",
      "Original label :  1\n",
      "After conversion to categorical ( one-hot ) :  [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "nRows,nCols = train_images.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data = train_images.reshape(train_images.shape[0], nRows, nCols, 1)\n",
    "test_data = test_images.reshape(test_images.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "print(len(train_labels))\n",
    "print(len(test_labels))\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    "print('Original label : ', train_labels[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[56])\n",
    "print('Original label : ', test_labels[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(2, activation='softmax')(den)\n",
    "    return out\n",
    "\n",
    "encode = encoder(input)\n",
    "full_model = Model(input,fc(encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model.layers[:14],autoencoder.layers[0:14]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model.layers[0:14]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 1.5086 - acc: 0.7090 - val_loss: 1.4135 - val_acc: 0.7727\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.2726 - acc: 0.8060 - val_loss: 2.3226 - val_acc: 0.7727\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.4541 - acc: 0.8507 - val_loss: 1.6917 - val_acc: 0.8485\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.7979 - acc: 0.8955 - val_loss: 1.9342 - val_acc: 0.6667\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.2454 - acc: 0.8507 - val_loss: 1.8552 - val_acc: 0.6667\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.3050 - acc: 0.8657 - val_loss: 1.6529 - val_acc: 0.8485\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.5395 - acc: 0.7985 - val_loss: 1.6183 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 0.8636 - acc: 0.8881 - val_loss: 1.5248 - val_acc: 0.7879\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.8084 - acc: 0.8731 - val_loss: 1.6485 - val_acc: 0.7727\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6556 - acc: 0.9104 - val_loss: 1.6621 - val_acc: 0.7576\n"
     ]
    }
   ],
   "source": [
    "classify_train = full_model.fit(train_data, train_labels_one_hot, batch_size=32,epochs=10,verbose=1,validation_data=(test_data, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6621364029971035, 0.7575757575757576]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum']\n",
      "(5572, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5572, 28)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train2))\n",
    "p4=0\n",
    "d41=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train2 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs41=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs41 = np.append(imgs41, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d41.append(res)\n",
    "print(d41)\n",
    "    \n",
    "print(imgs41.shape)\n",
    "        \n",
    "img_data = np.array(imgs41)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "imgs441 = imgs41.reshape(-1,28,28,1)\n",
    "print(imgs441.shape)\n",
    "imgs441 = imgs441 / np.max(imgs441)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X1,valid_X1,train_ground1,valid_ground1 = train_test_split(imgs441,imgs441,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder1(input):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def decoder1(conv3):    \n",
    "    #decoder\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded\n",
    "\n",
    "\n",
    "autoencoder1 = Model(input, decoder1(encoder1(input)))\n",
    "autoencoder1.compile(loss='mean_squared_error', optimizer = 'rmsprop',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "159/159 [==============================] - 4s 27ms/step - loss: 0.1064 - acc: 0.0140 - val_loss: 0.0820 - val_acc: 0.0186\n",
      "Epoch 2/5\n",
      "159/159 [==============================] - 3s 16ms/step - loss: 0.0429 - acc: 0.0176 - val_loss: 0.0330 - val_acc: 0.0191\n",
      "Epoch 3/5\n",
      "159/159 [==============================] - 2s 15ms/step - loss: 0.0255 - acc: 0.0178 - val_loss: 0.0333 - val_acc: 0.0193\n",
      "Epoch 4/5\n",
      "159/159 [==============================] - 3s 17ms/step - loss: 0.0282 - acc: 0.0176 - val_loss: 0.0317 - val_acc: 0.0195\n",
      "Epoch 5/5\n",
      "159/159 [==============================] - 3s 16ms/step - loss: 0.0262 - acc: 0.0177 - val_loss: 0.0375 - val_acc: 0.0194\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train1 = autoencoder1.fit(train_X1, train_ground1, batch_size=32,epochs=5,verbose=1,validation_data=(valid_X1, valid_ground1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (133, 28, 28) 133\n",
      "Testing data shape :  (66, 28, 28) 66\n",
      "Total number of outputs :  4\n",
      "Output classes :  ['cat' 'dog' 'hor' 'hum']\n"
     ]
    }
   ],
   "source": [
    "imgs41 = np.reshape(imgs41, [ 199, 28, 28])\n",
    "imgs1 = np.reshape(imgs41, [ 199, 28, 28])\n",
    "train_images1, test_images1, train_labels1, test_labels1 = train_test_split(imgs41, d41, test_size=0.33, random_state=42)\n",
    "print('Training data shape : ', train_images1.shape, len(train_labels1))\n",
    "print('Testing data shape : ', test_images1.shape, len(test_labels1))\n",
    "classes = np.unique(train_labels1)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels1=[0 if x=='dog' else 1 for x in train_labels1]\n",
    "print(train_labels1)\n",
    "len(train_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels1=[0 if x=='dog' else 1 for x in test_labels1]\n",
    "print(test_labels1)\n",
    "len(test_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "133\n",
      "66\n",
      "Original label :  1\n",
      "After conversion to categorical ( one-hot ) :  [0. 1.]\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "nRows,nCols = train_images1.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data1 = train_images1.reshape(train_images1.shape[0], nRows, nCols, 1)\n",
    "test_data1 = test_images1.reshape(test_images1.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data1 = train_data1.astype('float32')\n",
    "test_data1 = test_data1.astype('float32')\n",
    "train_data1 /= 255\n",
    "test_data1 /= 255\n",
    "print(len(train_labels1))\n",
    "print(len(test_labels1))\n",
    "train_labels_one_hot1 = to_categorical(train_labels1)\n",
    "test_labels_one_hot1 = to_categorical(test_labels1)\n",
    "print('Original label : ', train_labels1[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot1[56])\n",
    "print('Original label : ', test_labels1[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot1[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(2, activation='softmax')(den)\n",
    "    return out\n",
    "\n",
    "encode1 = encoder1(input)\n",
    "full_model1 = Model(input,fc(encode1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model1.layers[:14],autoencoder1.layers[0:14]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model1.layers[0:14]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 133 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "133/133 [==============================] - 1s 11ms/step - loss: 1.7606 - acc: 0.7444 - val_loss: 3.0464 - val_acc: 0.8030\n",
      "Epoch 2/10\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 1.6868 - acc: 0.8571 - val_loss: 1.8852 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 1.1927 - acc: 0.8496 - val_loss: 2.7950 - val_acc: 0.7727\n",
      "Epoch 4/10\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 1.1490 - acc: 0.8571 - val_loss: 2.6684 - val_acc: 0.7727\n",
      "Epoch 5/10\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.9418 - acc: 0.8571 - val_loss: 2.4836 - val_acc: 0.7879\n",
      "Epoch 6/10\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 0.9444 - acc: 0.9023 - val_loss: 2.8798 - val_acc: 0.7576\n",
      "Epoch 7/10\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 1.1438 - acc: 0.8571 - val_loss: 2.8485 - val_acc: 0.7576\n",
      "Epoch 8/10\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 1.3056 - acc: 0.9023 - val_loss: 2.9341 - val_acc: 0.7727\n",
      "Epoch 9/10\n",
      "133/133 [==============================] - 0s 4ms/step - loss: 1.3730 - acc: 0.8872 - val_loss: 2.8232 - val_acc: 0.7727\n",
      "Epoch 10/10\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.9703 - acc: 0.9098 - val_loss: 2.7449 - val_acc: 0.7424\n"
     ]
    }
   ],
   "source": [
    "classify_train1 = full_model1.fit(train_data1, train_labels_one_hot1, batch_size=32,epochs=10,verbose=1,validation_data=(test_data1, test_labels_one_hot1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7449387293873566, 0.7424242424242424]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model1.evaluate(test_data1, test_labels_one_hot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum']\n",
      "(5600, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5600, 28)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train3))\n",
    "p4=0\n",
    "d42=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train3 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs42=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs42 = np.append(imgs42, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d42.append(res)\n",
    "print(d42)\n",
    "    \n",
    "print(imgs42.shape)\n",
    "        \n",
    "img_data = np.array(imgs42)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "imgs442 = imgs42.reshape(-1,28,28,1)\n",
    "print(imgs442.shape)\n",
    "imgs442 = imgs442 / np.max(imgs442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X2,valid_X2,train_ground2,valid_ground2 = train_test_split(imgs442,imgs442,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder2(input):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def decoder2(conv3):    \n",
    "    #decoder\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded\n",
    "\n",
    "\n",
    "autoencoder2 = Model(input, decoder2(encoder2(input)))\n",
    "autoencoder2.compile(loss='mean_squared_error', optimizer = 'rmsprop',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 4s 23ms/step - loss: 0.1757 - acc: 0.0085 - val_loss: 0.1283 - val_acc: 8.6097e-04\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0529 - acc: 0.0155 - val_loss: 0.0301 - val_acc: 0.0016\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 2s 12ms/step - loss: 0.0465 - acc: 0.0153 - val_loss: 0.0351 - val_acc: 0.0014\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0281 - acc: 0.0164 - val_loss: 0.0166 - val_acc: 0.0016\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0207 - acc: 0.0163 - val_loss: 0.0094 - val_acc: 0.0016\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train2 = autoencoder2.fit(train_X2, train_ground2, batch_size=32,epochs=5,verbose=1,validation_data=(valid_X2, valid_ground2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (134, 28, 28) 134\n",
      "Testing data shape :  (66, 28, 28) 66\n",
      "Total number of outputs :  4\n",
      "Output classes :  ['cat' 'dog' 'hor' 'hum']\n"
     ]
    }
   ],
   "source": [
    "imgs42 = np.reshape(imgs42, [ 200, 28, 28])\n",
    "imgs1 = np.reshape(imgs42, [ 200, 28, 28])\n",
    "train_images2, test_images2, train_labels2, test_labels2 = train_test_split(imgs42, d42, test_size=0.33, random_state=42)\n",
    "print('Training data shape : ', train_images2.shape, len(train_labels2))\n",
    "print('Testing data shape : ', test_images2.shape, len(test_labels2))\n",
    "classes = np.unique(train_labels2)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels2=[0 if x=='hor' else 1 for x in train_labels2]\n",
    "print(train_labels2)\n",
    "len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels2=[0 if x=='hor' else 1 for x in test_labels2]\n",
    "print(test_labels2)\n",
    "len(test_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "134\n",
      "66\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "nRows,nCols = train_images2.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data2 = train_images2.reshape(train_images2.shape[0], nRows, nCols, 1)\n",
    "test_data2 = test_images2.reshape(test_images2.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data2 = train_data2.astype('float32')\n",
    "test_data2 = test_data2.astype('float32')\n",
    "train_data2 /= 255\n",
    "test_data2 /= 255\n",
    "print(len(train_labels2))\n",
    "print(len(test_labels2))\n",
    "train_labels_one_hot2 = to_categorical(train_labels2)\n",
    "test_labels_one_hot2 = to_categorical(test_labels2)\n",
    "print('Original label : ', train_labels2[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot2[56])\n",
    "print('Original label : ', test_labels2[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot2[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc1(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(2, activation='softmax')(den)\n",
    "    return out\n",
    "\n",
    "encode2 = encoder2(input)\n",
    "full_model2 = Model(input,fc1(encode2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model2.layers[:14],autoencoder2.layers[0:14]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model2.layers[0:14]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model2.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 2s 13ms/step - loss: 2.1194 - acc: 0.6343 - val_loss: 2.2622 - val_acc: 0.8485\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 2.5904 - acc: 0.8358 - val_loss: 2.2770 - val_acc: 0.8485\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 2.5989 - acc: 0.8358 - val_loss: 1.3560 - val_acc: 0.8636\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 2.5019 - acc: 0.8433 - val_loss: 0.3266 - val_acc: 0.8636\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.3872 - acc: 0.6940 - val_loss: 0.4471 - val_acc: 0.8788\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.6552 - acc: 0.8433 - val_loss: 3.5356 - val_acc: 0.4697\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.2479 - acc: 0.6269 - val_loss: 0.3467 - val_acc: 0.8182\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 1.5767 - acc: 0.8433 - val_loss: 1.2498 - val_acc: 0.4697\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.6163 - acc: 0.7985 - val_loss: 2.9614 - val_acc: 0.4697\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.6698 - acc: 0.7164 - val_loss: 0.3263 - val_acc: 0.8636\n"
     ]
    }
   ],
   "source": [
    "classify_train1 = full_model2.fit(train_data2, train_labels_one_hot2, batch_size=32,epochs=10,verbose=1,validation_data=(test_data2, test_labels_one_hot2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3263032470237125, 0.8636363636363636]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model2.evaluate(test_data2, test_labels_one_hot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan']\n",
      "(5600, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5600, 28)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train4))\n",
    "p4=0\n",
    "d43=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train4 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs43=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs43 = np.append(imgs43, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d43.append(res)\n",
    "print(d43)\n",
    "    \n",
    "print(imgs43.shape)\n",
    "        \n",
    "img_data = np.array(imgs43)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "imgs443 = imgs43.reshape(-1,28,28,1)\n",
    "print(imgs442.shape)\n",
    "imgs443 = imgs443 / np.max(imgs443)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X3,valid_X3,train_ground3,valid_ground3 = train_test_split(imgs443,imgs443,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder3(input):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def decoder3(conv3):    \n",
    "    #decoder\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded\n",
    "\n",
    "\n",
    "autoencoder3 = Model(input, decoder3(encoder3(input)))\n",
    "autoencoder3.compile(loss='mean_squared_error', optimizer = 'rmsprop',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 4s 26ms/step - loss: 0.1354 - acc: 0.0061 - val_loss: 0.0776 - val_acc: 0.0018\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0494 - acc: 0.0080 - val_loss: 0.0606 - val_acc: 0.0018\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 2s 14ms/step - loss: 0.0396 - acc: 0.0081 - val_loss: 0.0394 - val_acc: 0.0018\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0445 - acc: 0.0081 - val_loss: 0.0398 - val_acc: 0.0018\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0334 - acc: 0.0081 - val_loss: 0.0243 - val_acc: 0.0018\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train3 = autoencoder3.fit(train_X3, train_ground3, batch_size=32,epochs=5,verbose=1,validation_data=(valid_X3, valid_ground3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (134, 28, 28) 134\n",
      "Testing data shape :  (66, 28, 28) 66\n",
      "Total number of outputs :  5\n",
      "Output classes :  ['cat' 'dog' 'hor' 'hum' 'pan']\n"
     ]
    }
   ],
   "source": [
    "imgs43 = np.reshape(imgs43, [ 200, 28, 28])\n",
    "imgs1 = np.reshape(imgs43, [ 200, 28, 28])\n",
    "train_images3, test_images3, train_labels3, test_labels3 = train_test_split(imgs43, d43, test_size=0.33, random_state=42)\n",
    "print('Training data shape : ', train_images3.shape, len(train_labels3))\n",
    "print('Testing data shape : ', test_images3.shape, len(test_labels3))\n",
    "classes = np.unique(train_labels3)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels3=[0 if x=='hum' else 1 for x in train_labels3]\n",
    "print(train_labels3)\n",
    "len(train_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels3=[0 if x=='hum' else 1 for x in test_labels3]\n",
    "print(test_labels3)\n",
    "len(test_labels3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "134\n",
      "66\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "nRows,nCols = train_images3.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data3 = train_images3.reshape(train_images3.shape[0], nRows, nCols, 1)\n",
    "test_data3 = test_images3.reshape(test_images3.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data3 = train_data3.astype('float32')\n",
    "test_data3 = test_data3.astype('float32')\n",
    "train_data3 /= 255\n",
    "test_data3 /= 255\n",
    "print(len(train_labels3))\n",
    "print(len(test_labels3))\n",
    "train_labels_one_hot3 = to_categorical(train_labels3)\n",
    "test_labels_one_hot3 = to_categorical(test_labels3)\n",
    "print('Original label : ', train_labels3[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot3[56])\n",
    "print('Original label : ', test_labels3[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot3[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc2(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(2, activation='softmax')(den)\n",
    "    return out\n",
    "\n",
    "encode3 = encoder3(input)\n",
    "full_model3 = Model(input,fc2(encode3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model3.layers[:14],autoencoder3.layers[0:14]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model3.layers[0:14]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model3.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "134/134 [==============================] - 2s 15ms/step - loss: 1.6746 - acc: 0.8209 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 2/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.9407 - acc: 0.8731 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 3/10\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.9245 - acc: 0.8806 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 4/10\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.9361 - acc: 0.8731 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 5/10\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.9365 - acc: 0.8731 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 6/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.9245 - acc: 0.8806 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 7/10\n",
      "134/134 [==============================] - 0s 3ms/step - loss: 1.9245 - acc: 0.8806 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 8/10\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.9245 - acc: 0.8806 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 9/10\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.9287 - acc: 0.8806 - val_loss: 3.4190 - val_acc: 0.7879\n",
      "Epoch 10/10\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 1.9245 - acc: 0.8806 - val_loss: 3.4190 - val_acc: 0.7879\n"
     ]
    }
   ],
   "source": [
    "classify_train3 = full_model3.fit(train_data3, train_labels_one_hot3, batch_size=32,epochs=10,verbose=1,validation_data=(test_data3, test_labels_one_hot3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/66 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.4189900521076093, 0.7878787878787878]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model3.evaluate(test_data3, test_labels_one_hot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum']\n",
      "(22400, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22400, 28)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train_4))\n",
    "p4=0\n",
    "d_4=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train_4 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs_4=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs_4 = np.append(imgs_4, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d_4.append(res)\n",
    "print(d_4)\n",
    "    \n",
    "print(imgs_4.shape)\n",
    "        \n",
    "img_data = np.array(imgs_4)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (536, 28, 28) 536\n",
      "Testing data shape :  (264, 28, 28) 264\n",
      "Total number of outputs :  4\n",
      "Output classes :  ['cat' 'dog' 'hor' 'hum']\n"
     ]
    }
   ],
   "source": [
    "imgs_4 = np.reshape(imgs_4, [ 800, 28, 28])\n",
    "imgs1 = np.reshape(imgs_4, [ 800, 28, 28])\n",
    "train_images_4, test_images_4, train_labels_4, test_labels_4 = train_test_split(imgs_4, d_4, test_size=0.33, random_state=42)\n",
    "print('Training data shape : ', train_images_4.shape, len(train_labels_4))\n",
    "print('Testing data shape : ', test_images_4.shape, len(test_labels_4))\n",
    "classes = np.unique(train_labels_4)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 1, 0, 3, 2, 0, 0, 3, 1, 3, 0, 3, 3, 1, 3, 3, 1, 1, 3, 3, 0, 2, 1, 0, 1, 3, 2, 0, 2, 3, 0, 0, 1, 0, 3, 0, 3, 2, 2, 3, 3, 3, 0, 3, 0, 0, 0, 2, 2, 3, 0, 3, 3, 0, 2, 2, 1, 2, 3, 0, 0, 1, 1, 3, 3, 1, 3, 3, 2, 2, 1, 3, 0, 1, 0, 1, 3, 2, 2, 2, 1, 2, 1, 1, 0, 3, 1, 3, 1, 0, 2, 1, 0, 0, 3, 2, 1, 0, 3, 0, 1, 1, 0, 2, 0, 0, 2, 1, 1, 0, 2, 2, 2, 3, 1, 2, 0, 1, 2, 3, 3, 1, 1, 3, 0, 2, 2, 2, 3, 1, 1, 3, 1, 1, 3, 0, 1, 1, 3, 1, 0, 2, 2, 0, 0, 3, 3, 0, 3, 2, 3, 2, 0, 1, 3, 3, 2, 0, 0, 2, 2, 0, 3, 0, 3, 2, 3, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 0, 2, 1, 1, 2, 0, 3, 3, 1, 1, 0, 3, 0, 0, 0, 1, 1, 2, 3, 3, 1, 2, 0, 0, 3, 3, 1, 3, 1, 0, 3, 0, 1, 3, 0, 3, 1, 1, 0, 0, 1, 1, 3, 3, 3, 3, 2, 0, 0, 3, 2, 3, 0, 0, 1, 2, 3, 3, 2, 3, 2, 3, 0, 2, 0, 2, 0, 2, 0, 0, 3, 0, 2, 2, 3, 1, 3, 1, 0, 2, 3, 1, 1, 0, 2, 1, 3, 2, 2, 2, 0, 2, 2, 3, 2, 2, 2, 0, 2, 0, 3, 3, 2, 0, 1, 2, 0, 3, 3, 0, 0, 0, 3, 2, 1, 2, 2, 0, 2, 0, 3, 1, 1, 2, 3, 3, 1, 1, 3, 0, 2, 2, 3, 3, 0, 0, 3, 2, 2, 1, 3, 1, 0, 0, 2, 0, 2, 0, 1, 1, 3, 0, 0, 1, 3, 1, 3, 2, 0, 3, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 3, 1, 2, 3, 3, 0, 1, 2, 2, 1, 1, 2, 1, 3, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 3, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 0, 1, 0, 3, 0, 3, 0, 2, 2, 2, 2, 0, 3, 1, 3, 3, 3, 2, 1, 1, 1, 2, 1, 0, 2, 2, 2, 3, 0, 3, 3, 3, 0, 0, 1, 0, 0, 2, 1, 3, 1, 1, 3, 2, 1, 3, 3, 0, 0, 3, 2, 0, 2, 3, 0, 0, 0, 0, 3, 1, 0, 1, 0, 1, 1, 2, 1, 3, 3, 2, 1, 1, 0, 3, 3, 2, 3, 0, 3, 1, 0, 2, 3, 0, 1, 0, 3, 3, 3, 1, 0, 1, 3, 1, 1, 0, 1, 2, 1, 1, 0, 2, 2, 3, 2, 3, 1, 3, 3, 2, 0, 2, 3, 2, 3, 0, 3, 3, 2, 1, 0, 1, 3, 0, 1, 0, 1, 3, 3, 1, 2, 1, 2, 0, 2, 0, 1, 0, 3, 1, 1, 3, 0, 2, 0, 2, 0, 0, 1, 3, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "536"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_4=[0 if x=='cat' else 1 if x == 'dog' else 2 if x =='hum' else 3 for x in train_labels_4]\n",
    "print(train_labels_4)\n",
    "len(train_labels_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 0, 3, 0, 2, 1, 3, 2, 3, 0, 1, 2, 0, 1, 1, 1, 1, 2, 3, 2, 3, 2, 2, 1, 0, 1, 2, 2, 3, 1, 0, 3, 1, 0, 0, 2, 1, 2, 2, 0, 1, 0, 1, 3, 3, 3, 3, 2, 3, 1, 0, 2, 1, 1, 1, 3, 1, 0, 0, 3, 2, 2, 1, 1, 3, 0, 2, 1, 0, 3, 0, 2, 0, 0, 0, 1, 3, 3, 3, 3, 0, 0, 0, 3, 2, 2, 1, 1, 0, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 3, 0, 0, 0, 1, 1, 2, 1, 1, 3, 3, 0, 0, 2, 0, 3, 2, 1, 1, 1, 1, 0, 2, 1, 1, 3, 0, 1, 2, 2, 1, 0, 2, 1, 3, 2, 1, 2, 3, 1, 3, 3, 1, 0, 3, 0, 1, 2, 3, 2, 0, 2, 2, 3, 3, 2, 2, 3, 2, 1, 2, 1, 1, 1, 0, 0, 1, 1, 3, 1, 2, 0, 1, 1, 2, 0, 2, 2, 3, 2, 3, 0, 2, 2, 0, 3, 2, 3, 2, 3, 3, 1, 3, 3, 0, 2, 0, 2, 3, 1, 0, 0, 3, 0, 0, 0, 2, 1, 3, 2, 0, 0, 0, 0, 0, 3, 0, 1, 2, 2, 0, 2, 1, 0, 3, 0, 2, 2, 0, 3, 1, 0, 1, 1, 1, 3, 1, 0, 1, 3, 3, 2, 3, 0, 3, 0, 1, 0, 1, 3, 2, 1, 1, 3, 1, 0, 2, 1, 1, 0, 1, 2, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_4 =[0 if x=='cat' else 1 if x == 'dog' else 2 if x =='hum' else 3 for x in test_labels_4]\n",
    "print(test_labels_4)\n",
    "len(test_labels_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "536\n",
      "264\n",
      "Original label :  2\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 1. 0.]\n",
      "Original label :  3\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "nRows,nCols = train_images_4.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data_4 = train_images_4.reshape(train_images_4.shape[0], nRows, nCols, 1)\n",
    "test_data_4 = test_images_4.reshape(test_images_4.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data_4 = train_data_4.astype('float32')\n",
    "test_data_4 = test_data_4.astype('float32')\n",
    "train_data_4 /= 255\n",
    "test_data_4 /= 255\n",
    "print(len(train_labels_4))\n",
    "print(len(test_labels_4))\n",
    "train_labels_one_hot_4 = to_categorical(train_labels_4)\n",
    "test_labels_one_hot_4 = to_categorical(test_labels_4)\n",
    "print('Original label : ', train_labels_4[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot_4[56])\n",
    "print('Original label : ', test_labels_4[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot_4[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in autoencoder2.layers[0:14]:\n",
    "    layer.trainable =True\n",
    "for layer in autoencoder1.layers[0:14]:\n",
    "    layer.trainable =True\n",
    "for layer in autoencoder3.layers[0:14]:\n",
    "    layer.trainable =True\n",
    "for layer in autoencoder.layers[0:14]:\n",
    "    layer.trainable =True\n",
    "    \n",
    "from keras.layers import *\n",
    "\n",
    "a = Flatten()(encoder(input))\n",
    "b = Flatten()(encoder1(input))\n",
    "c = Flatten()(encoder2(input))\n",
    "d = Flatten()(encoder3(input))\n",
    "merged_model = concatenate([a,b,c,d])\n",
    "#merged_model1 = Dense(256, activation = 'relu')(merged_model1)\n",
    "merged_model1 = Dense(128, activation = 'relu')(merged_model)\n",
    "merged_model1 = Dense(4, activation = 'softmax')(merged_model1)\n",
    "model51 = Model(input,merged_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in autoencoder2.layers[0:14]:\n",
    "    layer.trainable =False\n",
    "for layer in autoencoder1.layers[0:14]:\n",
    "    layer.trainable =False\n",
    "for layer in autoencoder3.layers[0:14]:\n",
    "    layer.trainable =False\n",
    "for layer in autoencoder.layers[0:14]:\n",
    "    layer.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model51.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 536 samples, validate on 264 samples\n",
      "Epoch 1/20\n",
      "536/536 [==============================] - 23s 42ms/step - loss: 3.0880 - acc: 0.7285 - val_loss: 4.6876 - val_acc: 0.6212\n",
      "Epoch 2/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.8907 - acc: 0.7285 - val_loss: 2.4817 - val_acc: 0.7292\n",
      "Epoch 3/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.3625 - acc: 0.7649 - val_loss: 1.9890 - val_acc: 0.7633\n",
      "Epoch 4/20\n",
      "536/536 [==============================] - 19s 35ms/step - loss: 2.3459 - acc: 0.7687 - val_loss: 1.9664 - val_acc: 0.7670\n",
      "Epoch 5/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.3789 - acc: 0.7659 - val_loss: 2.1944 - val_acc: 0.7614\n",
      "Epoch 6/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.4117 - acc: 0.7771 - val_loss: 1.9694 - val_acc: 0.7633\n",
      "Epoch 7/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.3354 - acc: 0.7845 - val_loss: 2.2426 - val_acc: 0.7652\n",
      "Epoch 8/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.3206 - acc: 0.7901 - val_loss: 2.2254 - val_acc: 0.7652\n",
      "Epoch 9/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.4941 - acc: 0.7817 - val_loss: 2.0201 - val_acc: 0.7708\n",
      "Epoch 10/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.3088 - acc: 0.7892 - val_loss: 1.9946 - val_acc: 0.7765\n",
      "Epoch 11/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.3127 - acc: 0.7882 - val_loss: 2.0121 - val_acc: 0.7708\n",
      "Epoch 12/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.2887 - acc: 0.7966 - val_loss: 2.0190 - val_acc: 0.7633\n",
      "Epoch 13/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.2627 - acc: 0.8097 - val_loss: 1.9808 - val_acc: 0.7727\n",
      "Epoch 14/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.2509 - acc: 0.8153 - val_loss: 1.9686 - val_acc: 0.7614\n",
      "Epoch 15/20\n",
      "536/536 [==============================] - 19s 35ms/step - loss: 2.2408 - acc: 0.8209 - val_loss: 2.0001 - val_acc: 0.7879\n",
      "Epoch 16/20\n",
      "536/536 [==============================] - 19s 36ms/step - loss: 2.2438 - acc: 0.8209 - val_loss: 2.0159 - val_acc: 0.7670\n",
      "Epoch 17/20\n",
      "536/536 [==============================] - 20s 37ms/step - loss: 2.2702 - acc: 0.8284 - val_loss: 2.0101 - val_acc: 0.7784\n",
      "Epoch 18/20\n",
      "536/536 [==============================] - 19s 35ms/step - loss: 2.2426 - acc: 0.8237 - val_loss: 2.5168 - val_acc: 0.6477\n",
      "Epoch 19/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.2986 - acc: 0.8078 - val_loss: 2.2464 - val_acc: 0.7595\n",
      "Epoch 20/20\n",
      "536/536 [==============================] - 18s 34ms/step - loss: 2.2823 - acc: 0.8078 - val_loss: 2.2368 - val_acc: 0.7746\n"
     ]
    }
   ],
   "source": [
    "history3 = model51.fit(train_data_4,train_labels_one_hot_4,batch_size=32,epochs=20,validation_data=(test_data_4, test_labels_one_hot_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 28, 28, 32)   128         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 28, 28, 32)   128         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 28, 28, 32)   128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 28, 28, 32)   128         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 28, 28, 32)   128         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 28, 28, 32)   128         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 28, 28, 32)   128         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 28, 28, 32)   128         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 64)   256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 64)   256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 64)   256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 64)   256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 14, 14, 64)   256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 64)   256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 64)   256         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 128)    512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 7, 7, 128)    512         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 7, 7, 128)    512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 7, 7, 128)    512         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 128)    512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 7, 7, 128)    512         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 7, 7, 128)    512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 7, 7, 128)    512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 6272)         0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 6272)         0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 6272)         0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 6272)         0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 25088)        0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          3211392     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4)            516         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,364,804\n",
      "Trainable params: 4,361,220\n",
      "Non-trainable params: 3,584\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model51.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan']\n",
      "(5600, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5600, 28)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train5))\n",
    "p4=0\n",
    "d44=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train5 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs44=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs44 = np.append(imgs44, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d44.append(res)\n",
    "print(d44)\n",
    "    \n",
    "print(imgs44.shape)\n",
    "        \n",
    "img_data = np.array(imgs44)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "imgs444 = imgs44.reshape(-1,28,28,1)\n",
    "print(imgs444.shape)\n",
    "imgs444 = imgs444 / np.max(imgs444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X4,valid_X4,train_ground4,valid_ground4 = train_test_split(imgs444,imgs444,test_size=0.2,random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder4(input):\n",
    "    #encoder\n",
    "    #input = 28 x 28 x 1 (wide and thin)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input) #28 x 28 x 32\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPool2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPool2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    return conv3\n",
    "\n",
    "def decoder4(conv3):    \n",
    "    #decoder\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 64\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n",
    "    return decoded\n",
    "\n",
    "\n",
    "autoencoder4 = Model(input, decoder4(encoder4(input)))\n",
    "autoencoder4.compile(loss='mean_squared_error', optimizer = 'rmsprop',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/5\n",
      "160/160 [==============================] - 6s 35ms/step - loss: 0.0833 - acc: 0.0254 - val_loss: 0.0465 - val_acc: 0.0201\n",
      "Epoch 2/5\n",
      "160/160 [==============================] - 3s 16ms/step - loss: 0.0287 - acc: 0.0317 - val_loss: 0.0234 - val_acc: 0.0201\n",
      "Epoch 3/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0245 - acc: 0.0314 - val_loss: 0.0198 - val_acc: 0.0201\n",
      "Epoch 4/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0206 - acc: 0.0317 - val_loss: 0.0272 - val_acc: 0.0202\n",
      "Epoch 5/5\n",
      "160/160 [==============================] - 2s 13ms/step - loss: 0.0187 - acc: 0.0318 - val_loss: 0.0167 - val_acc: 0.0202\n"
     ]
    }
   ],
   "source": [
    "autoencoder_train4 = autoencoder4.fit(train_X4, train_ground4, batch_size=32,epochs=5,verbose=1,validation_data=(valid_X4, valid_ground4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (134, 28, 28) 134\n",
      "Testing data shape :  (66, 28, 28) 66\n",
      "Total number of outputs :  4\n",
      "Output classes :  ['cat' 'dog' 'hor' 'pan']\n"
     ]
    }
   ],
   "source": [
    "imgs44 = np.reshape(imgs44, [ 200, 28, 28])\n",
    "imgs1 = np.reshape(imgs44, [ 200, 28, 28])\n",
    "train_images4, test_images4, train_labels4, test_labels4 = train_test_split(imgs44, d44, test_size=0.33, random_state=42)\n",
    "print('Training data shape : ', train_images4.shape, len(train_labels4))\n",
    "print('Testing data shape : ', test_images4.shape, len(test_labels4))\n",
    "classes = np.unique(train_labels4)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels4=[0 if x=='pan' else 1 for x in train_labels4]\n",
    "print(train_labels4)\n",
    "len(train_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels4=[0 if x=='pan' else 1 for x in test_labels4]\n",
    "print(test_labels4)\n",
    "len(test_labels4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "134\n",
      "66\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "nRows,nCols = train_images4.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data4 = train_images4.reshape(train_images4.shape[0], nRows, nCols, 1)\n",
    "test_data4 = test_images4.reshape(test_images4.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data4 = train_data4.astype('float32')\n",
    "test_data4 = test_data4.astype('float32')\n",
    "train_data4 /= 255\n",
    "test_data4 /= 255\n",
    "print(len(train_labels4))\n",
    "print(len(test_labels4))\n",
    "train_labels_one_hot4 = to_categorical(train_labels4)\n",
    "test_labels_one_hot4 = to_categorical(test_labels4)\n",
    "print('Original label : ', train_labels4[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot4[56])\n",
    "print('Original label : ', test_labels4[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot4[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc3(enco):\n",
    "    flat = Flatten()(enco)\n",
    "    den = Dense(128, activation='relu')(flat)\n",
    "    out = Dense(2, activation='softmax')(den)\n",
    "    return out\n",
    "\n",
    "encode4 = encoder4(input)\n",
    "full_model4 = Model(input,fc3(encode4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(full_model4.layers[:14],autoencoder4.layers[0:14]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in full_model4.layers[0:14]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model4.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 66 samples\n",
      "Epoch 1/5\n",
      "134/134 [==============================] - 3s 23ms/step - loss: 1.9662 - acc: 0.5896 - val_loss: 3.4354 - val_acc: 0.6212\n",
      "Epoch 2/5\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.7219 - acc: 0.7239 - val_loss: 2.5532 - val_acc: 0.5909\n",
      "Epoch 3/5\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.2140 - acc: 0.7313 - val_loss: 1.7404 - val_acc: 0.6212\n",
      "Epoch 4/5\n",
      "134/134 [==============================] - 1s 4ms/step - loss: 0.8671 - acc: 0.7985 - val_loss: 2.0834 - val_acc: 0.5455\n",
      "Epoch 5/5\n",
      "134/134 [==============================] - 0s 4ms/step - loss: 1.0708 - acc: 0.7612 - val_loss: 1.9439 - val_acc: 0.7121\n"
     ]
    }
   ],
   "source": [
    "classify_train4 = full_model4.fit(train_data4,train_labels_one_hot4,batch_size=32,epochs=5,validation_data=(test_data4, test_labels_one_hot4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan']\n",
      "(28000, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28000, 28)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = sorted(os.listdir(train_5))\n",
    "p4=0\n",
    "d_5=[]\n",
    "for img_name in filenames:\n",
    "    img = plt.imread(train_5 + img_name)\n",
    "    img  = np.resize(img, (28,28))\n",
    "    if p4==0:\n",
    "      imgs_5=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs_5 = np.append(imgs_5, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d_5.append(res)\n",
    "print(d_5)\n",
    "    \n",
    "print(imgs_5.shape)\n",
    "        \n",
    "img_data = np.array(imgs_5)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (670, 28, 28) 670\n",
      "Testing data shape :  (330, 28, 28) 330\n",
      "Total number of outputs :  5\n",
      "Output classes :  ['cat' 'dog' 'hor' 'hum' 'pan']\n"
     ]
    }
   ],
   "source": [
    "imgs_5 = np.reshape(imgs_5, [ 1000, 28, 28])\n",
    "imgs1 = np.reshape(imgs_5, [ 1000, 28, 28])\n",
    "train_images_5, test_images_5, train_labels_5, test_labels_5 = train_test_split(imgs_5, d_5, test_size=0.33, random_state=42)\n",
    "print('Training data shape : ', train_images_5.shape, len(train_labels_5))\n",
    "print('Testing data shape : ', test_images_5.shape, len(test_labels_5))\n",
    "classes = np.unique(train_labels_5)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 2, 2, 0, 1, 2, 3, 4, 3, 3, 3, 0, 0, 1, 3, 3, 4, 0, 4, 0, 1, 4, 0, 1, 0, 1, 3, 1, 0, 3, 3, 0, 3, 0, 0, 2, 0, 1, 4, 0, 2, 0, 0, 0, 2, 3, 0, 4, 4, 1, 0, 2, 1, 1, 4, 3, 0, 4, 2, 0, 0, 2, 0, 3, 0, 3, 3, 2, 4, 0, 3, 3, 3, 2, 2, 4, 1, 0, 3, 3, 4, 2, 1, 4, 2, 2, 4, 3, 3, 0, 2, 3, 3, 3, 1, 0, 0, 2, 1, 1, 1, 1, 3, 1, 0, 0, 1, 4, 2, 1, 3, 4, 2, 3, 3, 2, 0, 2, 2, 3, 4, 1, 0, 1, 2, 4, 2, 1, 3, 0, 0, 3, 4, 1, 0, 0, 3, 3, 3, 3, 0, 4, 0, 1, 4, 4, 4, 2, 3, 2, 0, 0, 1, 3, 0, 0, 1, 0, 3, 4, 3, 2, 0, 3, 0, 3, 3, 4, 4, 2, 0, 1, 4, 2, 4, 2, 1, 4, 2, 1, 3, 1, 0, 1, 2, 1, 0, 4, 0, 1, 2, 4, 1, 3, 3, 4, 1, 2, 0, 3, 0, 2, 1, 4, 3, 0, 0, 2, 3, 0, 1, 1, 3, 0, 4, 3, 4, 3, 0, 0, 3, 2, 0, 4, 4, 1, 1, 0, 1, 0, 4, 4, 2, 1, 3, 2, 1, 1, 4, 0, 0, 2, 0, 1, 4, 0, 3, 1, 2, 1, 0, 4, 2, 4, 3, 3, 2, 0, 0, 1, 4, 2, 2, 4, 0, 1, 2, 3, 2, 0, 0, 1, 1, 2, 4, 0, 0, 2, 2, 0, 1, 2, 2, 2, 2, 4, 3, 4, 0, 4, 0, 4, 0, 0, 3, 0, 4, 4, 3, 4, 3, 1, 2, 4, 1, 0, 4, 3, 4, 1, 1, 0, 4, 1, 3, 4, 4, 2, 4, 0, 4, 4, 3, 4, 4, 3, 4, 0, 4, 0, 4, 4, 2, 0, 1, 2, 0, 3, 3, 2, 3, 2, 2, 0, 0, 0, 3, 4, 1, 2, 4, 2, 0, 4, 0, 3, 2, 1, 1, 2, 3, 2, 2, 4, 1, 2, 1, 3, 0, 2, 2, 4, 3, 4, 3, 0, 0, 2, 4, 2, 2, 1, 3, 1, 0, 0, 4, 2, 0, 4, 0, 2, 1, 1, 3, 0, 0, 1, 3, 1, 3, 4, 2, 4, 4, 4, 0, 2, 3, 2, 2, 2, 4, 1, 2, 4, 2, 4, 4, 2, 4, 2, 1, 4, 3, 1, 4, 3, 3, 0, 2, 1, 4, 2, 2, 1, 4, 4, 1, 2, 2, 1, 2, 3, 4, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 4, 4, 3, 1, 3, 2, 4, 4, 4, 2, 4, 4, 2, 4, 3, 4, 3, 2, 0, 1, 2, 0, 3, 0, 3, 0, 2, 4, 4, 4, 4, 2, 0, 3, 1, 2, 3, 2, 3, 3, 4, 1, 1, 2, 1, 2, 4, 1, 0, 2, 2, 4, 2, 2, 3, 2, 2, 0, 4, 2, 3, 3, 3, 0, 0, 2, 4, 1, 0, 0, 4, 1, 3, 2, 1, 1, 3, 2, 1, 3, 3, 0, 0, 3, 2, 0, 4, 3, 4, 4, 0, 4, 0, 0, 0, 3, 1, 0, 2, 1, 2, 0, 4, 1, 2, 2, 2, 1, 2, 1, 2, 3, 3, 4, 4, 4, 1, 1, 0, 3, 2, 3, 2, 3, 4, 2, 0, 3, 1, 0, 4, 4, 3, 0, 1, 0, 2, 3, 3, 3, 1, 0, 1, 4, 3, 1, 2, 1, 0, 1, 2, 1, 1, 0, 4, 4, 2, 4, 3, 4, 3, 4, 1, 3, 4, 3, 2, 0, 2, 2, 3, 2, 3, 0, 3, 3, 4, 2, 1, 0, 1, 3, 0, 1, 4, 0, 1, 4, 3, 3, 1, 2, 1, 2, 0, 2, 4, 0, 1, 0, 3, 1, 1, 3, 0, 2, 0, 2, 0, 0, 1, 4, 3, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_5=[0 if x=='cat' else 1 if x == 'dog' else 2 if x =='hum' else 3 if x =='hor' else 4 for x in train_labels_5]\n",
    "print(train_labels_5)\n",
    "len(train_labels_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 2, 2, 3, 2, 2, 3, 4, 0, 4, 0, 2, 4, 4, 4, 1, 4, 2, 1, 3, 0, 1, 3, 1, 1, 0, 4, 4, 4, 1, 0, 2, 3, 1, 0, 2, 3, 4, 0, 1, 0, 1, 4, 1, 1, 4, 2, 3, 4, 3, 4, 1, 3, 0, 0, 2, 0, 1, 4, 1, 0, 3, 1, 2, 2, 2, 4, 0, 3, 0, 3, 3, 2, 1, 1, 2, 0, 3, 1, 2, 0, 1, 0, 1, 3, 4, 2, 2, 1, 1, 3, 3, 1, 2, 3, 2, 0, 0, 4, 2, 1, 4, 1, 2, 2, 3, 4, 0, 4, 3, 4, 4, 4, 0, 3, 0, 4, 3, 1, 4, 3, 2, 1, 1, 3, 3, 3, 4, 4, 3, 4, 1, 4, 3, 0, 0, 1, 0, 0, 0, 1, 2, 1, 4, 4, 4, 1, 4, 1, 2, 0, 4, 3, 4, 3, 1, 2, 0, 4, 3, 2, 2, 2, 4, 2, 1, 2, 1, 1, 1, 3, 0, 4, 3, 1, 1, 1, 4, 2, 3, 2, 1, 3, 4, 0, 1, 1, 4, 2, 4, 4, 2, 0, 1, 3, 1, 1, 2, 0, 0, 3, 2, 3, 4, 3, 0, 4, 3, 4, 0, 0, 4, 4, 2, 1, 2, 1, 4, 2, 1, 2, 4, 0, 4, 0, 3, 1, 4, 3, 1, 4, 3, 3, 0, 0, 1, 4, 0, 1, 0, 1, 3, 2, 1, 0, 3, 0, 0, 1, 0, 4, 2, 4, 1, 1, 3, 4, 4, 0, 2, 3, 0, 1, 1, 4, 2, 1, 2, 1, 3, 0, 4, 1, 3, 0, 0, 2, 0, 2, 3, 2, 1, 1, 1, 2, 1, 3, 1, 4, 4, 2, 3, 3, 1, 3, 4, 3, 0, 0, 3, 3, 3, 3, 2, 4, 1, 3, 4, 3, 3, 3, 3, 2, 3, 3, 1, 1, 2, 1, 0, 0, 1, 2, 2, 3, 1, 3, 2, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_5=[0 if x=='cat' else 1 if x == 'dog' else 2 if x =='hum' else 3 if x =='hor' else 4 for x in test_labels_5]\n",
    "print(test_labels_5)\n",
    "len(test_labels_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "670\n",
      "330\n",
      "Original label :  3\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 0. 1. 0.]\n",
      "Original label :  2\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "nRows,nCols = train_images_5.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data_5 = train_images_5.reshape(train_images_5.shape[0], nRows, nCols, 1)\n",
    "test_data_5 = test_images_5.reshape(test_images_5.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data_5 = train_data_5.astype('float32')\n",
    "test_data_5 = test_data_5.astype('float32')\n",
    "train_data_5 /= 255\n",
    "test_data_5 /= 255\n",
    "print(len(train_labels_5))\n",
    "print(len(test_labels_5))\n",
    "train_labels_one_hot_5 = to_categorical(train_labels_5)\n",
    "test_labels_one_hot_5 = to_categorical(test_labels_5)\n",
    "print('Original label : ', train_labels_5[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot_5[56])\n",
    "print('Original label : ', test_labels_5[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot_5[56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model51.layers[0:62]:\n",
    "    layer.trainable =True\n",
    "for layer in autoencoder4.layers[0:14]:\n",
    "    layer.trainable =True\n",
    "    \n",
    "from keras.layers import *\n",
    "\n",
    "a = Flatten()(encoder(input))\n",
    "b = Flatten()(encoder1(input))\n",
    "c = Flatten()(encoder2(input))\n",
    "d = Flatten()(encoder3(input))\n",
    "e = Flatten()(encoder4(input))\n",
    "merged_model2 = concatenate([merged_model,e])\n",
    "#merged_model1 = Dense(256, activation = 'relu')(merged_model1)\n",
    "merged_model2 = Dense(128, activation = 'relu')(merged_model2)\n",
    "merged_model2 = Dense(5, activation = 'softmax')(merged_model2)\n",
    "model151 = Model(input,merged_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model51.layers[0:62]:\n",
    "    layer.trainable =False\n",
    "for layer in autoencoder4.layers[0:14]:\n",
    "    layer.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 28, 28, 32)   128         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 28, 28, 32)   128         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 28, 28, 32)   128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 28, 28, 32)   128         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, 28, 28, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 28, 28, 32)   9248        batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, 28, 28, 32)   128         conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 28, 28, 32)   128         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 28, 28, 32)   128         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 28, 28, 32)   128         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 28, 28, 32)   128         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, 28, 28, 32)   9248        batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, 28, 28, 32)   128         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 64)   18496       max_pooling2d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_127 (MaxPooling2D (None, 14, 14, 32)   0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 64)   256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 64)   256         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 64)   256         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 64)   256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, 14, 14, 64)   18496       max_pooling2d_127[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 64)   36928       batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, 14, 14, 64)   256         conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 64)   256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 14, 14, 64)   256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 64)   256         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 64)   256         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, 14, 14, 64)   36928       batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling2D) (None, 7, 7, 64)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 14, 14, 64)   256         conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 128)    73856       max_pooling2d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_128 (MaxPooling2D (None, 7, 7, 64)     0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 128)    512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 7, 7, 128)    512         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 7, 7, 128)    512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 7, 7, 128)    512         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, 7, 7, 128)    73856       max_pooling2d_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 7, 7, 128)    147584      batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 7, 7, 128)    512         conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 128)    512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 7, 7, 128)    512         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 7, 7, 128)    512         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 7, 7, 128)    512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, 7, 7, 128)    147584      batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 6272)         0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 6272)         0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 6272)         0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 6272)         0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 7, 7, 128)    512         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 25088)        0           flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_59 (Flatten)            (None, 6272)         0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 31360)        0           concatenate_1[0][0]              \n",
      "                                                                 flatten_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          4014208     concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 5)            645         dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,455,973\n",
      "Trainable params: 4,302,181\n",
      "Non-trainable params: 1,153,792\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model151.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model151.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670 samples, validate on 330 samples\n",
      "Epoch 1/20\n",
      "670/670 [==============================] - 23s 35ms/step - loss: 3.2323 - acc: 0.7749 - val_loss: 3.4988 - val_acc: 0.7794\n",
      "Epoch 2/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.2737 - acc: 0.7881 - val_loss: 3.6291 - val_acc: 0.7721\n",
      "Epoch 3/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.3121 - acc: 0.7845 - val_loss: 3.5973 - val_acc: 0.7685\n",
      "Epoch 4/20\n",
      "670/670 [==============================] - 14s 22ms/step - loss: 3.4375 - acc: 0.7821 - val_loss: 3.5957 - val_acc: 0.7733\n",
      "Epoch 5/20\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 3.3628 - acc: 0.7869 - val_loss: 3.6471 - val_acc: 0.7685\n",
      "Epoch 6/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.3510 - acc: 0.7875 - val_loss: 3.8489 - val_acc: 0.7539\n",
      "Epoch 7/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.5412 - acc: 0.7785 - val_loss: 4.0967 - val_acc: 0.7418\n",
      "Epoch 8/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4616 - acc: 0.7827 - val_loss: 3.9971 - val_acc: 0.7491\n",
      "Epoch 9/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.3897 - acc: 0.7869 - val_loss: 3.6089 - val_acc: 0.7733\n",
      "Epoch 10/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.5320 - acc: 0.7791 - val_loss: 3.5991 - val_acc: 0.7661\n",
      "Epoch 11/20\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 3.5875 - acc: 0.7755 - val_loss: 4.2773 - val_acc: 0.7285\n",
      "Epoch 12/20\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 3.5566 - acc: 0.7755 - val_loss: 3.4535 - val_acc: 0.7842\n",
      "Epoch 13/20\n",
      "670/670 [==============================] - 16s 23ms/step - loss: 3.8868 - acc: 0.7558 - val_loss: 3.6288 - val_acc: 0.7733\n",
      "Epoch 14/20\n",
      "670/670 [==============================] - 16s 24ms/step - loss: 3.7923 - acc: 0.7618 - val_loss: 3.5752 - val_acc: 0.7770\n",
      "Epoch 15/20\n",
      "670/670 [==============================] - 16s 25ms/step - loss: 3.8680 - acc: 0.7576 - val_loss: 3.5582 - val_acc: 0.7770\n",
      "Epoch 16/20\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 3.8981 - acc: 0.7564 - val_loss: 3.5752 - val_acc: 0.7770\n",
      "Epoch 17/20\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 3.9474 - acc: 0.7528 - val_loss: 3.5752 - val_acc: 0.7770\n",
      "Epoch 18/20\n",
      "670/670 [==============================] - 17s 25ms/step - loss: 3.9680 - acc: 0.7510 - val_loss: 3.5558 - val_acc: 0.7782\n",
      "Epoch 19/20\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 3.7684 - acc: 0.7630 - val_loss: 3.5260 - val_acc: 0.7758\n",
      "Epoch 20/20\n",
      "670/670 [==============================] - 16s 24ms/step - loss: 3.4272 - acc: 0.7833 - val_loss: 4.7334 - val_acc: 0.7030\n"
     ]
    }
   ],
   "source": [
    "history1 = model151.fit(train_data_5,train_labels_one_hot_5,batch_size=32,epochs=20,validation_data=(test_data_5, test_labels_one_hot_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model151.layers[0:76]:\n",
    "    layer.trainable =True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 670 samples, validate on 330 samples\n",
      "Epoch 1/20\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 3.4592 - acc: 0.7821 - val_loss: 3.3640 - val_acc: 0.7624\n",
      "Epoch 2/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4053 - acc: 0.7857 - val_loss: 3.6464 - val_acc: 0.7697\n",
      "Epoch 3/20\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 3.4445 - acc: 0.7839 - val_loss: 3.4841 - val_acc: 0.7818\n",
      "Epoch 4/20\n",
      "670/670 [==============================] - 16s 24ms/step - loss: 3.3971 - acc: 0.7857 - val_loss: 3.4479 - val_acc: 0.7842\n",
      "Epoch 5/20\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 3.3679 - acc: 0.7893 - val_loss: 3.4300 - val_acc: 0.7842\n",
      "Epoch 6/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4319 - acc: 0.7839 - val_loss: 3.6728 - val_acc: 0.7709\n",
      "Epoch 7/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4656 - acc: 0.7827 - val_loss: 3.6777 - val_acc: 0.7685\n",
      "Epoch 8/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4860 - acc: 0.7815 - val_loss: 3.7830 - val_acc: 0.7624\n",
      "Epoch 9/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.3765 - acc: 0.7881 - val_loss: 3.4579 - val_acc: 0.7818\n",
      "Epoch 10/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.2302 - acc: 0.7982 - val_loss: 3.5039 - val_acc: 0.7794\n",
      "Epoch 11/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.2982 - acc: 0.7934 - val_loss: 3.4646 - val_acc: 0.7830\n",
      "Epoch 12/20\n",
      "670/670 [==============================] - 14s 22ms/step - loss: 3.4010 - acc: 0.7863 - val_loss: 3.4254 - val_acc: 0.7855\n",
      "Epoch 13/20\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 3.3272 - acc: 0.7916 - val_loss: 3.5327 - val_acc: 0.7782\n",
      "Epoch 14/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.7035 - acc: 0.7684 - val_loss: 3.8084 - val_acc: 0.7624\n",
      "Epoch 15/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.7468 - acc: 0.7660 - val_loss: 3.4781 - val_acc: 0.7830\n",
      "Epoch 16/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4730 - acc: 0.7827 - val_loss: 3.4302 - val_acc: 0.7855\n",
      "Epoch 17/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4709 - acc: 0.7833 - val_loss: 3.4359 - val_acc: 0.7830\n",
      "Epoch 18/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4439 - acc: 0.7851 - val_loss: 3.4568 - val_acc: 0.7842\n",
      "Epoch 19/20\n",
      "670/670 [==============================] - 14s 21ms/step - loss: 3.4261 - acc: 0.7857 - val_loss: 3.5169 - val_acc: 0.7806\n",
      "Epoch 20/20\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 3.5445 - acc: 0.7779 - val_loss: 3.5083 - val_acc: 0.7806\n"
     ]
    }
   ],
   "source": [
    "history1 = model151.fit(train_data_5,train_labels_one_hot_5,batch_size=32,epochs=20,validation_data=(test_data_5, test_labels_one_hot_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
