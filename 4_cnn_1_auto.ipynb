{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from random import randint\n",
    "import cv2\n",
    "from keras.layers import MaxPool2D,Conv2D,UpSampling2D,Flatten\n",
    "from keras.layers import Dense,Input\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = \"C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\train_new\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum', 'hum']\n",
      "(153600, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(153600, 256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames2 = sorted(os.listdir(train))\n",
    "p42=0\n",
    "d42=[]\n",
    "for img_name in filenames2:\n",
    "    img = plt.imread(train + img_name)\n",
    "    img  = np.resize(img, (256, 256))\n",
    "    if p42==0:\n",
    "      imgs42=(img)\n",
    "      p42=1\n",
    "    else:\n",
    "      imgs42 = np.append(imgs42, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d42.append(res)\n",
    "print(d42)\n",
    "    \n",
    "print(imgs42.shape)\n",
    "        \n",
    "img_data = np.array(imgs42)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 256, 256)\n",
      "(120, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "imgs42 = np.reshape(imgs42, [ 600, 256, 256])\n",
    "train_images2, test_images2 = train_test_split(imgs42,test_size=0.20, random_state=42)\n",
    "nRows,nCols = train_images2.shape[1:]\n",
    "nDims = nRows\n",
    "train_data2 = train_images2.reshape(train_images2.shape[0], nRows, nCols, 1)\n",
    "test_data2 = test_images2.reshape(test_images2.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data2 = train_data2.astype('float32')\n",
    "test_data2 = test_data2.astype('float32')\n",
    "train_data2 /= 255\n",
    "test_data2 /= 255\n",
    "print(train_images2.shape)\n",
    "print(test_images2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (480, 256, 256) 480\n",
      "Testing data shape :  (120, 256, 256) 120\n",
      "Total number of outputs :  4\n",
      "Output classes :  ['cat' 'dog' 'hor' 'hum']\n"
     ]
    }
   ],
   "source": [
    "imgs2 = np.reshape(imgs42, [ 600, 256, 256])\n",
    "train_images2, test_images2, train_labels2, test_labels2 = train_test_split(imgs42, d42, test_size=0.20, random_state=42)\n",
    "print('Training data shape : ', train_images2.shape, len(train_labels2))\n",
    "print('Testing data shape : ', test_images2.shape, len(test_labels2))\n",
    "classes2 = np.unique(train_labels2)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses2 = len(classes2)\n",
    "\n",
    "print('Total number of outputs : ', nClasses2)\n",
    "print('Output classes : ', classes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 2, 3, 1, 0, 3, 1, 3, 2, 0, 3, 1, 1, 3, 1, 0, 0, 1, 0, 0, 1, 1, 0, 3, 0, 2, 2, 0, 0, 3, 3, 2, 2, 3, 1, 0, 2, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 3, 2, 1, 1, 3, 2, 1, 0, 3, 0, 0, 1, 0, 1, 3, 3, 2, 2, 2, 3, 2, 1, 3, 3, 0, 1, 2, 1, 3, 2, 3, 0, 0, 2, 3, 1, 1, 1, 1, 1, 1, 2, 3, 3, 3, 0, 1, 0, 2, 0, 3, 0, 1, 3, 0, 2, 2, 3, 2, 2, 0, 2, 0, 2, 1, 3, 3, 0, 2, 1, 2, 1, 3, 2, 2, 1, 0, 2, 3, 2, 1, 0, 0, 0, 1, 3, 0, 0, 2, 1, 0, 1, 1, 2, 3, 1, 2, 3, 1, 0, 1, 2, 2, 2, 0, 0, 2, 3, 3, 0, 0, 3, 3, 0, 3, 2, 2, 2, 2, 1, 0, 2, 1, 0, 1, 0, 1, 1, 3, 1, 3, 2, 1, 3, 3, 3, 0, 2, 1, 2, 1, 1, 1, 3, 2, 3, 2, 0, 2, 0, 2, 3, 0, 2, 2, 3, 1, 2, 2, 2, 2, 0, 2, 0, 0, 1, 2, 3, 0, 0, 2, 2, 1, 3, 1, 1, 1, 3, 3, 0, 2, 2, 1, 2, 0, 3, 3, 0, 2, 2, 2, 3, 0, 3, 0, 0, 1, 2, 0, 2, 1, 1, 3, 0, 1, 1, 2, 1, 3, 3, 3, 3, 3, 2, 0, 3, 1, 2, 0, 1, 0, 3, 2, 2, 3, 2, 3, 2, 2, 3, 1, 3, 3, 2, 0, 1, 2, 3, 2, 2, 2, 1, 3, 1, 2, 3, 1, 2, 0, 2, 1, 3, 1, 1, 0, 0, 3, 2, 2, 1, 3, 3, 2, 0, 3, 1, 3, 0, 0, 3, 2, 0, 3, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 0, 0, 1, 0, 1, 3, 3, 1, 3, 0, 0, 1, 3, 2, 3, 1, 3, 3, 0, 3, 3, 1, 2, 1, 2, 2, 1, 1, 0, 1, 3, 3, 2, 0, 1, 2, 3, 3, 1, 2, 1, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 0, 0, 3, 3, 1, 3, 1, 2, 1, 2, 2, 3, 0, 0, 3, 0, 3, 3, 0, 0, 1, 0, 3, 2, 1, 1, 0, 2, 1, 1, 3, 3, 3, 1, 1, 1, 2, 3, 0, 2, 0, 3, 0, 1, 0, 3, 2, 3, 2, 0, 2, 2, 1, 0, 2, 2, 1, 1, 3, 3, 3, 3, 1, 3, 1, 3, 3, 0, 3, 3, 1, 0, 2, 3, 1, 1, 1, 2, 2, 3, 2, 2, 0, 0, 2, 0, 3, 2, 1, 3, 0, 0, 0, 0, 1, 2, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels2=[0 if x=='cat' else 1 if x=='dog' else 2 if x=='hor' else 3 for x in train_labels2]\n",
    "print(train_labels2)\n",
    "len(train_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 3, 0, 1, 1, 0, 3, 0, 2, 0, 0, 0, 3, 2, 1, 0, 1, 1, 0, 0, 3, 3, 3, 2, 3, 0, 0, 3, 2, 3, 1, 0, 1, 1, 3, 0, 3, 2, 1, 2, 0, 3, 3, 0, 1, 3, 0, 0, 3, 1, 1, 0, 3, 3, 2, 1, 1, 0, 1, 0, 1, 2, 3, 3, 0, 3, 3, 0, 2, 2, 0, 2, 2, 2, 3, 2, 1, 3, 2, 1, 2, 3, 2, 0, 0, 1, 1, 2, 1, 1, 3, 0, 2, 1, 1, 1, 0, 2, 0, 0, 1, 3, 2, 0, 2, 0, 1, 1, 2, 1, 3, 3, 3, 2, 2, 2, 0, 3, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels2=[0 if x=='cat' else 1 if x=='dog' else 2 if x=='hor' else 3 for x in test_labels2]\n",
    "print(test_labels2)\n",
    "len(test_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "480\n",
      "120\n",
      "Original label :  3\n",
      "After conversion to categorical ( one-hot ) :  [0. 0. 0. 1.]\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "nRows,nCols = train_images2.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data2 = train_images2.reshape(train_images2.shape[0], nRows, nCols, 1)\n",
    "test_data2 = test_images2.reshape(test_images2.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data2 = train_data2.astype('float32')\n",
    "test_data2 = test_data2.astype('float32')\n",
    "train_data2 /= 255\n",
    "test_data2 /= 255\n",
    "print(len(train_labels2))\n",
    "print(len(test_labels2))\n",
    "train_labels_one_hot2 = to_categorical(train_labels2)\n",
    "test_labels_one_hot2 = to_categorical(test_labels2)\n",
    "print('Original label : ', train_labels2[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot2[56])\n",
    "print('Original label : ', test_labels2[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape =(256,256, 1))\n",
    "x = Conv2D(32, kernel_size = (3, 3), activation='relu')(input)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(64, kernel_size=(3,3), activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation='relu')(x) \n",
    "x = MaxPool2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "\n",
    "layer2 = Flatten()(x)\n",
    "layer2 = Dense(256, activation = 'relu')(layer2)\n",
    "layer2 = Dropout(0.2)(layer2)\n",
    "layer2 = Dense(128, activation = 'relu')(layer2)\n",
    "layer2 = Dense(4, activation = 'softmax')(layer2)\n",
    "model1 = Model(input,layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy',optimizer ='adam',metrics =['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 480 samples, validate on 120 samples\n",
      "Epoch 1/20\n",
      "480/480 [==============================] - 365s 761ms/step - loss: 0.4552 - acc: 0.7479 - val_loss: 0.3585 - val_acc: 0.7375\n",
      "Epoch 2/20\n",
      "480/480 [==============================] - 362s 753ms/step - loss: 0.3659 - acc: 0.7521 - val_loss: 0.3491 - val_acc: 0.7500\n",
      "Epoch 3/20\n",
      "480/480 [==============================] - 399s 831ms/step - loss: 0.3645 - acc: 0.7510 - val_loss: 0.3684 - val_acc: 0.7542\n",
      "Epoch 4/20\n",
      "480/480 [==============================] - 351s 732ms/step - loss: 0.3562 - acc: 0.7510 - val_loss: 0.3512 - val_acc: 0.7625\n",
      "Epoch 5/20\n",
      "480/480 [==============================] - 348s 725ms/step - loss: 0.3569 - acc: 0.7240 - val_loss: 0.3512 - val_acc: 0.7375\n",
      "Epoch 6/20\n",
      "480/480 [==============================] - 354s 737ms/step - loss: 0.3541 - acc: 0.7469 - val_loss: 0.3543 - val_acc: 0.7375\n",
      "Epoch 7/20\n",
      "480/480 [==============================] - 348s 725ms/step - loss: 0.3537 - acc: 0.7333 - val_loss: 0.3487 - val_acc: 0.7458\n",
      "Epoch 8/20\n",
      "480/480 [==============================] - 349s 726ms/step - loss: 0.3526 - acc: 0.7349 - val_loss: 0.3478 - val_acc: 0.7479\n",
      "Epoch 9/20\n",
      "480/480 [==============================] - 351s 731ms/step - loss: 0.3532 - acc: 0.7380 - val_loss: 0.3465 - val_acc: 0.7583\n",
      "Epoch 10/20\n",
      "480/480 [==============================] - 349s 728ms/step - loss: 0.3518 - acc: 0.7443 - val_loss: 0.3468 - val_acc: 0.7625\n",
      "Epoch 11/20\n",
      "480/480 [==============================] - 352s 733ms/step - loss: 0.3756 - acc: 0.7594 - val_loss: 0.6793 - val_acc: 0.7500\n",
      "Epoch 12/20\n",
      "480/480 [==============================] - 349s 728ms/step - loss: 0.4863 - acc: 0.7510 - val_loss: 0.3482 - val_acc: 0.7458\n",
      "Epoch 13/20\n",
      "480/480 [==============================] - 351s 731ms/step - loss: 0.3557 - acc: 0.7271 - val_loss: 0.3511 - val_acc: 0.7458\n",
      "Epoch 14/20\n",
      "480/480 [==============================] - 357s 744ms/step - loss: 0.3509 - acc: 0.7380 - val_loss: 0.3483 - val_acc: 0.7458\n",
      "Epoch 15/20\n",
      "480/480 [==============================] - 341s 711ms/step - loss: 0.3517 - acc: 0.7339 - val_loss: 0.3497 - val_acc: 0.7542\n",
      "Epoch 16/20\n",
      "480/480 [==============================] - 340s 709ms/step - loss: 0.3526 - acc: 0.7448 - val_loss: 0.3481 - val_acc: 0.7375\n",
      "Epoch 17/20\n",
      "480/480 [==============================] - 338s 704ms/step - loss: 0.3499 - acc: 0.7219 - val_loss: 0.3511 - val_acc: 0.7458\n",
      "Epoch 18/20\n",
      "480/480 [==============================] - 336s 700ms/step - loss: 0.3509 - acc: 0.7542 - val_loss: 0.3473 - val_acc: 0.7396\n",
      "Epoch 19/20\n",
      "480/480 [==============================] - 336s 700ms/step - loss: 0.3497 - acc: 0.7563 - val_loss: 0.3465 - val_acc: 0.7625\n",
      "Epoch 20/20\n",
      "480/480 [==============================] - 335s 697ms/step - loss: 0.3497 - acc: 0.7448 - val_loss: 0.3470 - val_acc: 0.7458\n"
     ]
    }
   ],
   "source": [
    "history3 = model1.fit(train_data2,train_labels_one_hot2,batch_size=1,epochs=20,validation_data=(test_data2, test_labels_one_hot2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 5s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34700954556465147, 0.7458333293596904]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_data2,test_labels_one_hot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = \"C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\train_new1\\\\\"\n",
    "train2 = \"C:\\\\Users\\\\JYOTHI PRASANNA\\\\Desktop\\\\train_new_2\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'hor', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan', 'pan']\n",
      "(51200, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51200, 256)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames2 = sorted(os.listdir(train1))\n",
    "p4=0\n",
    "d4=[]\n",
    "for img_name in filenames2:\n",
    "    img = plt.imread(train1 + img_name)\n",
    "    img  = np.resize(img, (256, 256))\n",
    "    if p4==0:\n",
    "      imgs4=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs4 = np.append(imgs4, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d4.append(res)\n",
    "print(d4)\n",
    "    \n",
    "print(imgs4.shape)\n",
    "        \n",
    "img_data = np.array(imgs4)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 256, 256)\n",
      "(40, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "imgs4 = np.reshape(imgs4, [ 200, 256, 256])\n",
    "train_images1, test_images1 = train_test_split(imgs4,test_size=0.20, random_state=42)\n",
    "nRows,nCols = train_images1.shape[1:]\n",
    "nDims = nRows\n",
    "train_data1 = train_images1.reshape(train_images1.shape[0], nRows, nCols, 1)\n",
    "test_data1 = test_images1.reshape(test_images1.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data1 = train_data1.astype('float32')\n",
    "test_data1 = test_data1.astype('float32')\n",
    "train_data1 /= 255\n",
    "test_data1 /= 255\n",
    "print(train_images1.shape)\n",
    "print(test_images1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (160, 256, 256) 160\n",
      "Testing data shape :  (40, 256, 256) 40\n",
      "Total number of outputs :  4\n",
      "Output classes :  ['cat' 'dog' 'hor' 'pan']\n"
     ]
    }
   ],
   "source": [
    "imgs2 = np.reshape(imgs4, [ 200, 256, 256])\n",
    "train_images1, test_images1, train_labels1, test_labels1 = train_test_split(imgs4, d4, test_size=0.20, random_state=42)\n",
    "print('Training data shape : ', train_images1.shape, len(train_labels1))\n",
    "print('Testing data shape : ', test_images1.shape, len(test_labels1))\n",
    "classes = np.unique(train_labels1)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels1=[0 if x=='pan' else 1 for x in train_labels1]\n",
    "print(train_labels1)\n",
    "len(train_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels1=[0 if x=='pan' else 1 for x in test_labels1]\n",
    "print(test_labels1)\n",
    "len(test_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "160\n",
      "40\n",
      "Original label :  0\n",
      "After conversion to categorical ( one-hot ) :  [1. 0.]\n",
      "Original label :  1\n",
      "After conversion to categorical ( one-hot ) :  [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "nRows,nCols = train_images1.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data1 = train_images1.reshape(train_images1.shape[0], nRows, nCols, 1)\n",
    "test_data1 = test_images1.reshape(test_images1.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data1 = train_data1.astype('float32')\n",
    "test_data1 = test_data1.astype('float32')\n",
    "train_data1 /= 255\n",
    "test_data1 /= 255\n",
    "print(len(train_labels1))\n",
    "print(len(test_labels1))\n",
    "train_labels_one_hot1 = to_categorical(train_labels1)\n",
    "test_labels_one_hot1 = to_categorical(test_labels1)\n",
    "print('Original label : ', train_labels1[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot1[56])\n",
    "print('Original label : ', test_labels1[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder2(value):\n",
    "    net11 = Conv2D(32,(3,3),activation ='relu',padding='same')(value)\n",
    "    net11 = BatchNormalization()(net11)\n",
    "    net11 = Conv2D(32,(3,3),activation ='relu',padding='same')(net11)\n",
    "    net11 = BatchNormalization()(net11)\n",
    "    net11= MaxPool2D(pool_size=(2,2))(net11)\n",
    "    net11 = Conv2D(64,(3,3),activation ='relu',padding='same')(net11)\n",
    "    net11 = BatchNormalization()(net11)\n",
    "    net11 = Conv2D(64,(3,3),activation ='relu',padding='same')(net11)\n",
    "\n",
    "    return net11\n",
    "\n",
    "def decoder2(value2):\n",
    "    net12 = Conv2D(32,(3,3),activation ='relu',padding='same')(encoder2(value2))\n",
    "    net12 = BatchNormalization()(net12)\n",
    "    net12 = Conv2D(32,(3,3),activation ='relu',padding='same')(net12)\n",
    "    net12 = UpSampling2D((2,2))(net12)\n",
    "    decoded1 = Conv2D(1,(3,3),activation = 'sigmoid',padding ='same')(net12)\n",
    "    \n",
    "    return decoded1\n",
    "\n",
    "flat1 =Flatten()(decoder2(input))\n",
    "out1 = Dense(2, activation='softmax')(flat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder1 = Model(input, out1)\n",
    "autoencoder1.compile(loss ='mean_squared_error',optimizer ='rmsprop',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160 samples, validate on 40 samples\n",
      "Epoch 1/20\n",
      "160/160 [==============================] - 200s 1s/step - loss: 0.4576 - acc: 0.4875 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 2/20\n",
      "160/160 [==============================] - 185s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 3/20\n",
      "160/160 [==============================] - 185s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 4/20\n",
      "160/160 [==============================] - 173s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 5/20\n",
      "160/160 [==============================] - 189s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 6/20\n",
      "160/160 [==============================] - 213s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 7/20\n",
      "160/160 [==============================] - 211s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 8/20\n",
      "160/160 [==============================] - 210s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 9/20\n",
      "160/160 [==============================] - 209s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 10/20\n",
      "160/160 [==============================] - 3160s 20s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 11/20\n",
      "160/160 [==============================] - 219s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 12/20\n",
      "160/160 [==============================] - 219s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 13/20\n",
      "160/160 [==============================] - 216s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 14/20\n",
      "160/160 [==============================] - 215s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 15/20\n",
      "160/160 [==============================] - 219s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 16/20\n",
      "160/160 [==============================] - 889s 6s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 17/20\n",
      "160/160 [==============================] - 196s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 18/20\n",
      "160/160 [==============================] - 211s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 19/20\n",
      "160/160 [==============================] - 212s 1s/step - loss: 0.4937 - acc: 0.5062 - val_loss: 0.5250 - val_acc: 0.4750\n",
      "Epoch 20/20\n",
      " 96/160 [=================>............] - ETA: 1:21 - loss: 0.4792 - acc: 0.5208"
     ]
    }
   ],
   "source": [
    "classify_train11 = autoencoder1.fit(train_data1,train_labels_one_hot1,batch_size=32,epochs=20,verbose=1,validation_data = (test_data1,test_labels_one_hot1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer21 = Flatten()(encoder2(input))\n",
    "layer21 = Dense(256, activation = 'relu')(layer21)\n",
    "layer21 = Dense(128, activation = 'relu')(layer21)\n",
    "layer21 = Dense(2, activation = 'softmax')(layer21)\n",
    "model12 = Model(input,layer21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1,l2 in zip(model12.layers[:9],autoencoder1.layers[0:9]):\n",
    "    l1.set_weights(l2.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model12.layers[0:9]:\n",
    "    layer.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model12.compile(loss='binary_crossentropy',optimizer ='adam',metrics =['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_train12 = model12.fit(train_data1,train_labels_one_hot1,batch_size=32,epochs=20,verbose=1,validation_data = (test_data1,test_labels_one_hot1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Flatten()(x)\n",
    "b = Flatten()(encoder2(input))\n",
    "merged_model1 = concatenate([a,b])\n",
    "merged_model1 = Dense(256, activation = 'relu')(merged_model1)\n",
    "merged_model1 = Dense(128, activation = 'relu')(merged_model1)\n",
    "merged_model1 = Dense(2, activation = 'softmax')(merged_model1)\n",
    "model51 = Model(input,merged_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames2 = sorted(os.listdir(train2))\n",
    "p4=0\n",
    "d41=[]\n",
    "for img_name in filenames2:\n",
    "    img = plt.imread(train2 + img_name)\n",
    "    img  = np.resize(img, (256, 256))\n",
    "    if p4==0:\n",
    "      imgs41=(img)\n",
    "      p4=1\n",
    "    else:\n",
    "      imgs41 = np.append(imgs41, img, axis=0)\n",
    "    res = img_name[:3]\n",
    "    d41.append(res)\n",
    "print(d41)\n",
    "    \n",
    "print(imgs41.shape)\n",
    "        \n",
    "img_data = np.array(imgs41)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data = img_data/255\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs41 = np.reshape(imgs41, [ 500, 256, 256])\n",
    "train_images,test_images = train_test_split(imgs41,test_size=0.20, random_state=42)\n",
    "nRows,nCols = train_images.shape[1:]\n",
    "nDims = nRows\n",
    "train_data = train_images.reshape(train_images.shape[0], nRows, nCols, 1)\n",
    "test_data = test_images.reshape(test_images.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs2 = np.reshape(imgs41, [ 500, 256, 256])\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(imgs41, d41, test_size=0.20, random_state=42)\n",
    "print('Training data shape : ', train_images.shape, len(train_labels))\n",
    "print('Testing data shape : ', test_images.shape, len(test_labels))\n",
    "classes = np.unique(train_labels)\n",
    "#classes=np.append(classes,0)\n",
    "nClasses = len(classes)\n",
    "\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=[0 if x=='pan' else 1 if x=='cat' else 2 if x=='dog' else 3 if x =='hor' else 4 for x in train_labels]\n",
    "print(train_labels)\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels=[0 if x=='pan' else 1 if x=='cat' else 2 if x=='dog' else 3 if x =='hor' else 4 for x in test_labels]\n",
    "print(test_labels)\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "nRows,nCols = train_images.shape[1:]\n",
    "nDims = nRows\n",
    "print(nCols)\n",
    "train_data = train_images.reshape(train_images.shape[0], nRows, nCols, 1)\n",
    "test_data = test_images.reshape(test_images.shape[0], nRows, nCols, 1)\n",
    "input_shape = (nRows, nCols, 1)\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "print(len(train_labels))\n",
    "print(len(test_labels))\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    "print('Original label : ', train_labels[56])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[56])\n",
    "print('Original label : ', test_labels[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', test_labels_one_hot[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
